# Generated 2024-02-03 from:
# /fastdata/acq22mc/exp/dasr/dasr/tts/speechbrain/recipes/LJSpeech/TTS/fastspeech2/hparams/train_internal_alignment.yaml
# yamllint disable
############################################################################
# Model: FastSpeech2 with internal alignment
# Tokens: Phonemes (ARPABET)
# Dataset: LJSpeech
# Authors: Yingzhi Wang 2023
# ############################################################################

###################################
# Experiment Parameters and setup #
###################################
seed: 1234
__set_seed: !apply:torch.manual_seed [1234]
output_folder: results/fastspeech2_internal_alignment/1234
save_folder: results/fastspeech2_internal_alignment/1234/save
train_log: results/fastspeech2_internal_alignment/1234/train_log.txt
epochs: 500
progress_samples: true
progress_sample_path: results/fastspeech2_internal_alignment/1234/samples
progress_samples_min_run: 10
progress_samples_interval: 10
progress_batch_sample_size: 4

#################################
# Data files and pre-processing #
#################################
data_folder: /fastdata/acq22mc/data/dysarthria/Torgo_use
                          # e.g., /data/Database/LJSpeech-1.1

train_json: results/fastspeech2_internal_alignment/1234/save/train.json
valid_json: results/fastspeech2_internal_alignment/1234/save/valid.json
test_json: results/fastspeech2_internal_alignment/1234/save/test.json

splits: [train, valid]
split_ratio: [90, 10]

skip_prep: false

################################
# Audio Parameters             #
################################
sample_rate: 22050
hop_length: 256
win_length:
n_mel_channels: 80
n_fft: 1024
mel_fmin: 0.0
mel_fmax: 8000.0
power: 1
norm: slaney
mel_scale: slaney
dynamic_range_compression: true
mel_normalized: false
min_max_energy_norm: true
min_f0: 65  #(torchaudio pyin values)
max_f0: 2093 #(torchaudio pyin values)

################################
# Optimization Hyperparameters #
################################
learning_rate: 0.0001
weight_decay: 0.000001
max_grad_norm: 1.0
batch_size: 16 #minimum 2
betas: &id003 [0.9, 0.998]

num_workers_train: 16
num_workers_valid: 4

################################
# Model Parameters and model   #
################################
# Input parameters
lexicon:
- AA
- AE
- AH
- AO
- AW
- AY
- B
- CH
- D
- DH
- EH
- ER
- EY
- F
- G
- HH
- IH
- IY
- JH
- K
- L
- M
- N
- NG
- OW
- OY
- P
- R
- S
- SH
- T
- TH
- UH
- UW
- V
- W
- Y
- Z
- ZH
- '-'
- '!'
- "'"
- (
- )
- ','
- .
- ':'
- ;
- '?'
- ' '

n_symbols: 52 #fixed depending on symbols in the lexicon (+1 for a dummy symbol used for padding, +1 for unknown)
padding_idx: 0

hidden_channels: 512
# Encoder parameters
enc_num_layers: 4
enc_num_head: 2
enc_d_model: 512
enc_ffn_dim: 1024
enc_k_dim: 512
enc_v_dim: 512
enc_dropout: 0.2

# Aligner parameters
in_query_channels: 80
in_key_channels: 512                    # 512 in the paper
attn_channels: 80
temperature: 0.0005

# Decoder parameters
dec_num_layers: 4
dec_num_head: 2
dec_d_model: 512
dec_ffn_dim: 1024
dec_k_dim: 512
dec_v_dim: 512
dec_dropout: 0.2

# Postnet parameters
postnet_embedding_dim: 512
postnet_kernel_size: 5
postnet_n_convolutions: 5
postnet_dropout: 0.2

# common
normalize_before: true
ffn_type: 1dcnn #1dcnn or ffn
ffn_cnn_kernel_size_list: &id001 [9, 1]

# variance predictor
dur_pred_kernel_size: 3
pitch_pred_kernel_size: 3
energy_pred_kernel_size: 3
variance_predictor_dropout: 0.5

#model
model: &id002 !new:speechbrain.lobes.models.FastSpeech2.FastSpeech2WithAlignment

  enc_num_layers: 4
  enc_num_head: 2
  enc_d_model: 512
  enc_ffn_dim: 1024
  enc_k_dim: 512
  enc_v_dim: 512
  enc_dropout: 0.2
  in_query_channels: 80
  in_key_channels: 512
  attn_channels: 80
  temperature: 0.0005
  dec_num_layers: 4
  dec_num_head: 2
  dec_d_model: 512
  dec_ffn_dim: 1024
  dec_k_dim: 512
  dec_v_dim: 512
  dec_dropout: 0.2
  normalize_before: true
  ffn_type: 1dcnn
  ffn_cnn_kernel_size_list: *id001
  n_char: 52
  n_mels: 80
  postnet_embedding_dim: 512
  postnet_kernel_size: 5
  postnet_n_convolutions: 5
  postnet_dropout: 0.2
  padding_idx: 0
  dur_pred_kernel_size: 3
  pitch_pred_kernel_size: 3
  energy_pred_kernel_size: 3
  variance_predictor_dropout: 0.5

mel_spectogram: !name:speechbrain.lobes.models.FastSpeech2.mel_spectogram
  sample_rate: 22050
  hop_length: 256
  win_length:
  n_fft: 1024
  n_mels: 80
  f_min: 0.0
  f_max: 8000.0
  power: 1
  normalized: false
  min_max_energy_norm: true
  norm: slaney
  mel_scale: slaney
  compression: true

criterion: !new:speechbrain.lobes.models.FastSpeech2.LossWithAlignment
  log_scale_durations: true
  duration_loss_weight: 1.0
  pitch_loss_weight: 1.0
  energy_loss_weight: 1.0
  ssim_loss_weight: 1.0
  mel_loss_weight: 1.0
  postnet_mel_loss_weight: 1.0
  aligner_loss_weight: 1.0
  binary_alignment_loss_weight: 0.2
  binary_alignment_loss_warmup_epochs: 1
  binary_alignment_loss_max_epochs: 80

vocoder: hifi-gan
pretrained_vocoder: true
vocoder_source: speechbrain/tts-hifigan-ljspeech
vocoder_download_path: tmpdir_vocoder

modules:
  model: *id002
train_dataloader_opts:
  batch_size: 16
  drop_last: false    #True #False
  num_workers: 16
  shuffle: true
  collate_fn: !new:speechbrain.lobes.models.FastSpeech2.TextMelCollateWithAlignment

valid_dataloader_opts:
  batch_size: 16
  num_workers: 4
  shuffle: false
  collate_fn: !new:speechbrain.lobes.models.FastSpeech2.TextMelCollateWithAlignment

#optimizer
opt_class: !name:torch.optim.Adam
  lr: 0.0001
  weight_decay: 0.000001
  betas: *id003
noam_annealing: &id004 !new:speechbrain.nnet.schedulers.NoamScheduler
  lr_initial: 0.0001
  n_warmup_steps: 4000


#epoch object
epoch_counter: &id005 !new:speechbrain.utils.epoch_loop.EpochCounter

  limit: 500

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: results/fastspeech2_internal_alignment/1234/train_log.txt

#checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: results/fastspeech2_internal_alignment/1234/save
  recoverables:
    model: *id002
    lr_annealing: *id004
    counter: *id005
input_encoder: !new:speechbrain.dataio.encoder.TextEncoder

progress_sample_logger: !new:speechbrain.utils.train_logger.ProgressSampleLogger
  output_path: results/fastspeech2_internal_alignment/1234/samples
  batch_sample_size: 4
  formats:
    raw_batch: raw
